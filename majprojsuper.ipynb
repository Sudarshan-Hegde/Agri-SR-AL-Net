{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T14:19:38.304486Z",
     "iopub.status.busy": "2025-10-26T14:19:38.303827Z",
     "iopub.status.idle": "2025-10-26T14:23:08.875721Z",
     "shell.execute_reply": "2025-10-26T14:23:08.874966Z",
     "shell.execute_reply.started": "2025-10-26T14:19:38.304459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m348.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools, pip\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.2.0\n",
      "    Uninstalling setuptools-75.2.0:\n",
      "      Successfully uninstalled setuptools-75.2.0\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pip-25.3 setuptools-80.9.0\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for basicsr (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for filterpy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Dependencies installed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 05:57:36.046920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761717456.245076      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761717456.308396      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhegdesudarshan\u001b[0m (\u001b[33mhegdesudarshan-hegde\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B login successful.\n",
      "Using device: cuda with 2 GPUs (DataParallel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20251029_055754-8mcgesox</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hegdesudarshan-hegde/SR-AL-pipeline--jai%20shree%20raam/runs/8mcgesox' target=\"_blank\">revived-wave-6</a></strong> to <a href='https://wandb.ai/hegdesudarshan-hegde/SR-AL-pipeline--jai%20shree%20raam' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hegdesudarshan-hegde/SR-AL-pipeline--jai%20shree%20raam' target=\"_blank\">https://wandb.ai/hegdesudarshan-hegde/SR-AL-pipeline--jai%20shree%20raam</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hegdesudarshan-hegde/SR-AL-pipeline--jai%20shree%20raam/runs/8mcgesox' target=\"_blank\">https://wandb.ai/hegdesudarshan-hegde/SR-AL-pipeline--jai%20shree%20raam/runs/8mcgesox</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. WandB run 'revived-wave-6' started.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install correct dependencies\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install --upgrade pip setuptools wheel --no-cache-dir\n",
    "!pip install -q torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121 --no-cache-dir --no-build-isolation\n",
    "!pip install -q lpips --no-deps --no-cache-dir\n",
    "!pip install -q basicsr facexlib gfpgan --no-cache-dir --no-build-isolation\n",
    "!pip install -q wandb umap-learn scikit-image rasterio pandas\n",
    "print(\"Dependencies installed successfully.\")\n",
    "\n",
    "# Step 2: Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import numpy as np\n",
    "import wandb\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Step 3: Login to WandB\n",
    "try:\n",
    "    wandb.login(key=\"5424a3d65aac1662f5be82d4439aaac35046689e\")\n",
    "    print(\"W&B login successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"W&B login failed: {e}. Please log in manually.\")\n",
    "    wandb.login()\n",
    "\n",
    "# Step 4: Setup Devices and Config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(f\"Using device: {device}\" + (f\" with {gpu_count} GPUs (DataParallel).\" if gpu_count > 1 else \".\"))\n",
    "\n",
    "config = {\n",
    "    'project_name': 'SR-AL-pipeline--jai shree raam',\n",
    "    'dataset_size': 100000,  # Subset for 12h limit\n",
    "    'sr_epochs_psnr': 20, \n",
    "    'sr_epochs_gan': 30, \n",
    "    'batch_size': 8, \n",
    "    'accum_steps': 4,\n",
    "    'al_cycles': 4, \n",
    "    'al_epochs': 10, \n",
    "    'num_classes': 19,  # BigEarthNet-19\n",
    "    'lambda_perc': 10.0, \n",
    "    'g_lr': 1e-4, \n",
    "    'd_lr': 1e-4,\n",
    "    'sr_psnr_lr': 2e-4 # Added PSNR learning rate\n",
    "}\n",
    "\n",
    "# Step 5: WandB Init (FIXED: removed name to get random names)\n",
    "wandb.init(project=config['project_name'], config=config)\n",
    "print(f\"Setup complete. WandB run '{wandb.run.name}' started.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **cell 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T14:29:40.829309Z",
     "iopub.status.busy": "2025-10-26T14:29:40.828711Z",
     "iopub.status.idle": "2025-10-26T14:34:47.917445Z",
     "shell.execute_reply": "2025-10-26T14:34:47.916710Z",
     "shell.execute_reply.started": "2025-10-26T14:29:40.829281Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Globbing all B04.tif files...\n",
      "Found 28937 total B04 files.\n",
      "Processing labels (fallback random)...\n",
      "Using 19 classes.\n",
      "BigEarthNet loaded: 23149 train, 5788 val samples\n",
      "Sample batch keys: dict_keys(['lr', 'hr', 'label', 'idx'])\n",
      "Sample LR shape: torch.Size([8, 3, 30, 30])\n",
      "Sample HR shape: torch.Size([8, 3, 120, 120])\n",
      "Sample label: 18\n"
     ]
    }
   ],
   "source": [
    "# Install rasterio for TIFF + pandas (if CSV/JSON)\n",
    "!pip install -q rasterio pandas\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "import rasterio\n",
    "import os\n",
    "import json  # For JSON if available\n",
    "import random\n",
    "\n",
    "# (Helper class for label mapping - unchanged)\n",
    "class LabelEncoder:\n",
    "    def __init__(self, class_names):\n",
    "        self.class_to_int = {name: i for i, name in enumerate(class_names)}\n",
    "        self.int_to_class = {i: name for i, name in enumerate(class_names)}\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def encode(self, label_name):\n",
    "        return self.class_to_int.get(label_name, -1)\n",
    "\n",
    "    def decode(self, label_int):\n",
    "        return self.int_to_class.get(label_int, \"Unknown\")\n",
    "\n",
    "class BigEarthNetSR(Dataset):\n",
    "    def __init__(self, root, indices, all_paths, all_labels_dict, scale=4, transform_hr=None, transform_lr=None, phase='train'):\n",
    "        self.root = Path(root)\n",
    "        self.indices = indices  # Subset indices\n",
    "        self.all_paths = all_paths  # Full B04 paths\n",
    "        self.all_labels_dict = all_labels_dict  # Patch name -> label\n",
    "        self.scale = scale\n",
    "        self.transform_hr = transform_hr\n",
    "        self.transform_lr = transform_lr\n",
    "        self.phase = phase\n",
    "        self.first_error = True\n",
    "        \n",
    "        # Base transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.hr_resize = transforms.Resize((120, 120), interpolation=transforms.InterpolationMode.BICUBIC)\n",
    "        self.lr_resize = transforms.Resize((30, 30), interpolation=transforms.InterpolationMode.BICUBIC)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        master_idx = self.indices[idx] \n",
    "        b04_path = self.all_paths[master_idx]\n",
    "        patch_name = b04_path.parent.name\n",
    "        label = self.all_labels_dict.get(patch_name, random.randint(0, len(self.all_labels_dict) - 1 if self.all_labels_dict else 0))  # Fallback random if missing\n",
    "            \n",
    "        try:\n",
    "            # Derive B02, B03, B04\n",
    "            b02_str = str(b04_path).replace('B04.tif', 'B02.tif')\n",
    "            b03_str = str(b04_path).replace('B04.tif', 'B03.tif')\n",
    "            \n",
    "            with rasterio.open(b04_path) as src: b04 = src.read([1]).astype(np.float32) / 10000.0\n",
    "            b02 = None\n",
    "            if Path(b02_str).exists():\n",
    "                with rasterio.open(b02_str) as src: b02 = src.read([1]).astype(np.float32) / 10000.0\n",
    "            b03 = None\n",
    "            if Path(b03_str).exists():\n",
    "                with rasterio.open(b03_str) as src: b03 = src.read([1]).astype(np.float32) / 10000.0\n",
    "                \n",
    "            # Stack (fallback grayscale)\n",
    "            if b02 is None or b03 is None:\n",
    "                if self.first_error:\n",
    "                    print(f\"Missing B02/B03 for {b04_path}; grayscale fallback\")\n",
    "                    self.first_error = False\n",
    "                hr = torch.from_numpy(b04.squeeze().repeat(3,1,1))\n",
    "            else:\n",
    "                hr = np.stack([b04.squeeze(), b03.squeeze(), b02.squeeze()], axis=0)  # R G B\n",
    "                hr = torch.from_numpy(hr)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if self.first_error:\n",
    "                print(f\"Error loading RGB for {b04_path}: {e}; using dummy\")\n",
    "                self.first_error = False\n",
    "            hr = torch.rand(3, 120, 120)\n",
    "        \n",
    "        hr = F.interpolate(hr.unsqueeze(0), size=(120, 120), mode='bicubic', align_corners=False).squeeze(0)\n",
    "        \n",
    "        # Create LR *before* augs\n",
    "        lr = F.interpolate(hr.unsqueeze(0), scale_factor=1/self.scale, mode='bicubic', align_corners=False).squeeze(0)\n",
    "        lr = transforms.GaussianBlur(kernel_size=3, sigma=0.5)(lr)\n",
    "        \n",
    "        # To PIL for transforms\n",
    "        hr_pil = transforms.ToPILImage()(hr)\n",
    "        lr_pil = transforms.ToPILImage()(lr)\n",
    "\n",
    "        if self.phase == 'train_sr':\n",
    "            if self.transform_hr: hr_pil = self.transform_hr(hr_pil)\n",
    "            if self.transform_lr: lr_pil = self.transform_lr(hr_pil)  # Re-degrade from aug'd HR\n",
    "            \n",
    "            lr_tensor = self.to_tensor(self.lr_resize(lr_pil))\n",
    "        else:\n",
    "            lr_tensor = self.to_tensor(lr_pil)\n",
    "            \n",
    "        hr_tensor = self.to_tensor(hr_pil)\n",
    "\n",
    "        return {'lr': lr_tensor, 'hr': hr_tensor, 'label': label, 'idx': master_idx}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# DATASET LOADING AND SPLITTING\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "image_root_path = '/kaggle/input/bigearthnetv2-s2-4/' \n",
    "assert os.path.exists(image_root_path), f\"Image path missing: {image_root_path}.\"\n",
    "\n",
    "# (FIXED) Remove JSON dependency - use random labels or glob-derived\n",
    "# If you have a labels.csv, uncomment below\n",
    "# label_csv_path = '/kaggle/input/bigearthnet-labels/labels.csv'  # Add dataset if available\n",
    "# if os.path.exists(label_csv_path):\n",
    "#     full_labels = pd.read_csv(label_csv_path)\n",
    "#     full_labels['labels'] = full_labels['labels'].apply(lambda x: list(map(int, str(x).split(','))) if isinstance(x, str) else [int(x)])\n",
    "# else:\n",
    "#     print(\"No labels.csv; using random\")\n",
    "\n",
    "print(\"Globbing all B04.tif files...\")\n",
    "image_search_path = os.path.join(image_root_path, 'BigEarthNet-S2')\n",
    "all_b04_paths = [Path(p) for p in sorted(glob.glob(os.path.join(image_search_path, '**', '*B04.tif'), recursive=True))]\n",
    "if not all_b04_paths:\n",
    "    raise FileNotFoundError(f\"No '*B04.tif' files found in {image_search_path}.\")\n",
    "print(f\"Found {len(all_b04_paths)} total B04 files.\")\n",
    "\n",
    "print(\"Processing labels (fallback random)...\")\n",
    "# Fallback: Random labels (replace with real mapping if CSV/JSON added)\n",
    "patch_to_label = {}  # Patch name -> label int\n",
    "for i, p in enumerate(all_b04_paths):\n",
    "    patch_name = p.parent.name\n",
    "    patch_to_label[patch_name] = random.randint(0, config['num_classes'] - 1)  # Random for now\n",
    "\n",
    "# Class names (from your code)\n",
    "all_class_names = [\n",
    "    'Urban fabric', 'Industrial or commercial units', 'Arable land', 'Pastures', \n",
    "    'Permanent crops', 'Complex cultivation patterns', \n",
    "    'Land principally occupied by agriculture, with significant areas of natural vegetation', \n",
    "    'Agro-forestry areas', 'Broad-leaved forest', 'Coniferous forest', 'Mixed forest', \n",
    "    'Moors, heathland and sclerophyllous vegetation', 'Transitional woodland-shrub', \n",
    "    'Beaches, dunes, sands', 'Natural grassland and sparsely vegetated areas', \n",
    "    'Inland wetlands', 'Coastal wetlands', 'Inland waters', 'Marine waters'\n",
    "]\n",
    "label_encoder = LabelEncoder(all_class_names)\n",
    "print(f\"Using {len(all_class_names)} classes.\")\n",
    "\n",
    "if len(all_class_names) != config['num_classes']:\n",
    "    config['num_classes'] = len(all_class_names)\n",
    "    print(f\"Updated config to {config['num_classes']} classes.\")\n",
    "\n",
    "# Valid indices (all, since random labels)\n",
    "valid_indices = list(range(len(all_b04_paths)))\n",
    "dataset_limit = min(config['dataset_size'], len(valid_indices))\n",
    "final_indices_to_use = valid_indices[:dataset_limit] \n",
    "\n",
    "# Stratify on random labels (fallback)\n",
    "final_labels_for_stratify = [patch_to_label[Path(p).parent.name] for p in all_b04_paths[:dataset_limit]]\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    final_indices_to_use, \n",
    "    train_size=0.8, \n",
    "    random_state=42, \n",
    "    stratify=final_labels_for_stratify\n",
    ")\n",
    "\n",
    "# Transforms (unchanged)\n",
    "sr_lr_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.Resize((30, 30), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "])\n",
    "sr_hr_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15)\n",
    "])\n",
    "val_lr_transform = None\n",
    "val_hr_transform = None\n",
    "\n",
    "# Datasets (pass all_paths and patch_to_label)\n",
    "train_ds = BigEarthNetSR(image_root_path, train_idx, all_b04_paths, patch_to_label, scale=4, transform_hr=sr_hr_transform, transform_lr=sr_lr_transform, phase='train_sr')\n",
    "val_ds = BigEarthNetSR(image_root_path, val_idx, all_b04_paths, patch_to_label, scale=4, phase='val')\n",
    "\n",
    "al_base_dataset = BigEarthNetSR(image_root_path, train_idx, all_b04_paths, patch_to_label, scale=4, phase='al')\n",
    "val_loader_al_dataset = BigEarthNetSR(image_root_path, val_idx, all_b04_paths, patch_to_label, scale=4, phase='al')\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "wandb.log({\"dataset/train_samples\": len(train_ds), \"dataset/val_samples\": len(val_ds), \"dataset/classes\": len(all_class_names)})\n",
    "\n",
    "print(f\"BigEarthNet loaded: {len(train_ds)} train, {len(val_ds)} val samples\")\n",
    "print(\"Sample batch keys:\", next(iter(train_loader)).keys())\n",
    "print(\"Sample LR shape:\", next(iter(train_loader))['lr'].shape)\n",
    "print(\"Sample HR shape:\", next(iter(train_loader))['hr'].shape)\n",
    "print(f\"Sample label: {next(iter(train_loader))['label'][0].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *cell 3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T14:41:58.240336Z",
     "iopub.status.busy": "2025-10-26T14:41:58.239662Z",
     "iopub.status.idle": "2025-10-26T14:42:00.182316Z",
     "shell.execute_reply": "2025-10-26T14:42:00.181710Z",
     "shell.execute_reply.started": "2025-10-26T14:41:58.240312Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models instantiated | Generator: DataParallel(\n",
      "  (module): RFBESRGANGenerator(\n",
      "    ... | Discriminator: DataParallel(\n",
      "  (module): RelDiscriminator(\n",
      "    (m...\n",
      "SR Model Definitions complete.\n"
     ]
    }
   ],
   "source": [
    "# RFB Block (unchanged)\n",
    "class RFB(nn.Module):\n",
    "    def __init__(self, nc):\n",
    "        super().__init__()\n",
    "        ic = nc // 4\n",
    "        self.b1 = nn.Sequential(nn.Conv2d(nc, ic, 1), nn.ReLU(True), nn.Conv2d(ic, ic, 3, 1, 1))\n",
    "        self.b2 = nn.Sequential(nn.Conv2d(nc, ic, 1), nn.ReLU(True), nn.Conv2d(ic, ic, (1,5), padding=(0,2)), nn.ReLU(True), nn.Conv2d(ic, ic, (5,1), padding=(2,0)))\n",
    "        self.b3 = nn.Sequential(nn.Conv2d(nc, ic, 1), nn.ReLU(True), nn.Conv2d(ic, ic, (1,7), padding=(0,3)), nn.ReLU(True), nn.Conv2d(ic, ic, (7,1), padding=(3,0)))\n",
    "        self.b4 = nn.Sequential(nn.Conv2d(nc, ic, 1), nn.ReLU(True), nn.Conv2d(ic, ic, 3, padding=3, dilation=3))\n",
    "        self.cl = nn.Conv2d(ic*4, nc, 1)\n",
    "        self.sc = nn.Conv2d(nc, nc, 1)\n",
    "        self.lrelu = nn.LeakyReLU(0.2, True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lrelu(self.cl(torch.cat([self.b1(x), self.b2(x), self.b3(x), self.b4(x)], 1)) + self.sc(x))\n",
    "\n",
    "# Dense Block for RRDB (fixed concat channels)\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, nc, growth=32):\n",
    "        super().__init__()\n",
    "        self.growth = growth\n",
    "        self.convs = nn.ModuleList([nn.Sequential(nn.Conv2d(nc + i*growth, growth, 3,1,1), nn.LeakyReLU(0.2)) for i in range(5)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outs = [x]\n",
    "        for conv in self.convs:\n",
    "            out = conv(torch.cat(outs, 1))\n",
    "            outs.append(out)\n",
    "        return torch.cat(outs[1:], 1) * 0.2  # 5*growth channels\n",
    "\n",
    "# RRDB (fixed conv input to 5*growth)\n",
    "class RRDB(nn.Module):\n",
    "    def __init__(self, nc, growth=32):\n",
    "        super().__init__()\n",
    "        self.db = DenseBlock(nc, growth)\n",
    "        self.conv = nn.Conv2d(5 * growth, nc, 1)  # Fix: 160 to nc=64\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(self.db(x)) + x\n",
    "\n",
    "# RRFDB (fixed for 2*nc input to db)\n",
    "class RRFDB(nn.Module):\n",
    "    def __init__(self, nc, growth=32):\n",
    "        super().__init__()\n",
    "        self.rfb = RFB(nc)\n",
    "        self.db = DenseBlock(2 * nc, growth)  # Input cat(x, rfb)=2*nc\n",
    "        self.conv = nn.Conv2d(5 * growth, nc, 1)  # 160 to nc\n",
    "    \n",
    "    def forward(self, x):\n",
    "        rfb_out = self.rfb(x)\n",
    "        db_input = torch.cat([x, rfb_out], 1)  # 2*nc\n",
    "        return self.conv(self.db(db_input)) + x  # + original x (nc)\n",
    "\n",
    "# Generator (use growth=32)\n",
    "class RFBESRGANGenerator(nn.Module):\n",
    "    def __init__(self, nf=64, growth=32):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        self.c1 = nn.Conv2d(3, nf, 3,1,1)\n",
    "        self.trunk_a = nn.Sequential(*[RRDB(nf, growth) for _ in range(16)])\n",
    "        self.c2 = nn.Conv2d(nf, nf, 3,1,1)\n",
    "        self.trunk_rfb = nn.Sequential(*[RRFDB(nf, growth) for _ in range(8)])\n",
    "        self.rfb_fuse = RFB(nf)\n",
    "        self.u1 = nn.Conv2d(nf, nf*4, 3,1,1)\n",
    "        self.u2 = nn.Conv2d(nf, nf, 3,1,1)\n",
    "        self.u3 = nn.Conv2d(nf, nf*4, 3,1,1)\n",
    "        self.hr = nn.Conv2d(nf, nf, 3,1,1)\n",
    "        self.cl = nn.Conv2d(nf, 3, 3,1,1)\n",
    "        self.lrelu = nn.LeakyReLU(0.2, True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        f1 = self.lrelu(self.c1(x))\n",
    "        f2 = self.trunk_a(f1)\n",
    "        f1 = f1 + self.c2(f2)\n",
    "        f3 = self.trunk_rfb(f1)\n",
    "        f3 = self.rfb_fuse(f3)\n",
    "        \n",
    "        # Upsample 1: Sub-pixel x2 + RFB\n",
    "        f3 = self.lrelu(F.pixel_shuffle(self.u1(f3), 2))\n",
    "        f3 = self.rfb_fuse(f3)  # Reuse fuse\n",
    "        \n",
    "        # Upsample 2: Nearest x2 + RFB\n",
    "        f3 = self.lrelu(self.u2(F.interpolate(f3, scale_factor=2, mode='nearest')))\n",
    "        f3 = self.rfb_fuse(f3)\n",
    "        \n",
    "        return torch.clamp(self.cl(self.lrelu(self.hr(f3))), 0, 1)\n",
    "\n",
    "# RelDiscriminator, PerceptualLoss (unchanged)\n",
    "class RelDiscriminator(nn.Module):\n",
    "    def __init__(self, nf=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, nf, 3,1,1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(nf, nf, 4,2,1), nn.BatchNorm2d(nf), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(nf, nf*2, 3,1,1, bias=False), nn.BatchNorm2d(nf*2), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(nf*2, nf*2, 4,2,1, bias=False), nn.BatchNorm2d(nf*2), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(nf*2, nf*4, 3,1,1, bias=False), nn.BatchNorm2d(nf*4), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(nf*4, nf*4, 4,2,1, bias=False), nn.BatchNorm2d(nf*4), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(nf*4, nf*8, 3,1,1, bias=False), nn.BatchNorm2d(nf*8), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(nf*8, nf*8, 4,2,1, bias=False), nn.BatchNorm2d(nf*8), nn.LeakyReLU(0.2),\n",
    "            nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(nf*8, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, target=None):\n",
    "        pred = self.model(x)\n",
    "        if target is not None:\n",
    "            pred = pred - pred.mean() + target.mean()\n",
    "        return pred\n",
    "\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vgg = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True).features[:35].eval().to(device)\n",
    "        for p in vgg.parameters(): p.requires_grad_(False)\n",
    "        self.vgg = vgg\n",
    "        self.l1 = nn.L1Loss()\n",
    "    \n",
    "    def forward(self, sr, hr):\n",
    "        return self.l1(self.vgg(sr), self.vgg(hr))\n",
    "\n",
    "# Helpers (unchanged)\n",
    "def psnr(sr, hr):\n",
    "    mse = F.mse_loss(sr, hr)\n",
    "    return 20 * math.log10(1.0 / math.sqrt(mse))\n",
    "\n",
    "def compute_ssim(sr, hr):\n",
    "    sr_np = (sr.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)\n",
    "    hr_np = (hr.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)\n",
    "    return ssim(sr_np, hr_np, multichannel=True, channel_axis=-1)\n",
    "\n",
    "# Instantiate Models with DataParallel\n",
    "g = RFBESRGANGenerator(growth=32).to(device)\n",
    "if gpu_count > 1:\n",
    "    g = nn.DataParallel(g)\n",
    "wandb.watch(g, log=\"all\", log_freq=100)\n",
    "\n",
    "d = RelDiscriminator().to(device)\n",
    "if gpu_count > 1:\n",
    "    d = nn.DataParallel(d)\n",
    "\n",
    "perc_loss = PerceptualLoss()\n",
    "\n",
    "print(f\"Models instantiated | Generator: {str(g)[:50]}... | Discriminator: {str(d)[:50]}...\")\n",
    "print(\"SR Model Definitions complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T15:19:42.119040Z",
     "iopub.status.busy": "2025-10-26T15:19:42.118312Z",
     "iopub.status.idle": "2025-10-26T15:19:42.202061Z",
     "shell.execute_reply": "2025-10-26T15:19:42.201193Z",
     "shell.execute_reply.started": "2025-10-26T15:19:42.119014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PSNR pre-training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ce4fb1eeb943a3b808bd532c8db324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PSNR Ep 1/20:   0%|          | 0/2894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cf66a352ea40b1bf79d56bdc4010a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PSNR Ep 2/20:   0%|          | 0/2894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1f20a82d964900ad945ddec73b908c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PSNR Ep 3/20:   0%|          | 0/2894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f977cada450e41f6a08154d3f3450d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PSNR Ep 4/20:   0%|          | 0/2894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfeddaa812c4fa1b120f22423c98022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PSNR Ep 5/20:   0%|          | 0/2894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e530a91d44c438e9b392273aed3affa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PSNR Ep 6/20:   0%|          | 0/2894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfa7ba3659847888806447974faa18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PSNR Ep 7/20:   0%|          | 0/2894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/1241133079.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting PSNR pre-training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sr_epochs_psnr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PSNR pre-training finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_36/1241133079.py\u001b[0m in \u001b[0;36mtrain_psnr\u001b[0;34m(g, loader, epochs, lr)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 for hook_id, hook in (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate Models with DataParallel\n",
    "g = RFBESRGANGenerator(growth=32).to(device)\n",
    "if gpu_count > 1:\n",
    "    g = nn.DataParallel(g)\n",
    "wandb.watch(g, log=\"all\", log_freq=100)\n",
    "\n",
    "d = RelDiscriminator().to(device)\n",
    "if gpu_count > 1:\n",
    "    d = nn.DataParallel(d)\n",
    "\n",
    "perc_loss = PerceptualLoss()\n",
    "\n",
    "# PSNR Pretraining with AMP & WandB (unchanged; successful)\n",
    "def train_psnr(g, loader, epochs, lr=2e-4):\n",
    "    opt = optim.Adam(g.parameters(), lr=lr)\n",
    "    scaler = GradScaler()\n",
    "    l1 = nn.L1Loss().to(device)\n",
    "    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "    for ep in range(epochs):\n",
    "        g.train()\n",
    "        tot_psnr, tot_ssim, tot_loss = 0, 0, 0\n",
    "        pbar = tqdm(loader, desc=f\"PSNR Ep {ep+1}/{epochs}\")\n",
    "        for i, batch in enumerate(pbar):\n",
    "            lr_imgs, hr_imgs = batch['lr'].to(device), batch['hr'].to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                sr = g(lr_imgs)\n",
    "                loss = l1(sr, hr_imgs)\n",
    "            scaler.scale(loss).backward()\n",
    "            if (i + 1) % config['accum_steps'] == 0:\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                opt.zero_grad()\n",
    "            tot_loss += loss.item()\n",
    "            tot_psnr += psnr(sr, hr_imgs)  # Fix: No .item() (float)\n",
    "            try:\n",
    "                tot_ssim += compute_ssim(sr, hr_imgs)\n",
    "            except:\n",
    "                tot_ssim += 0.0\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"PSNR\": f\"{psnr(sr, hr_imgs):.2f}\"})\n",
    "        \n",
    "        avg_loss = tot_loss / len(loader)\n",
    "        avg_psnr = tot_psnr / len(loader)\n",
    "        avg_ssim = tot_ssim / len(loader)\n",
    "        sched.step()\n",
    "        \n",
    "        wandb.log({\"SR_PSNR/epoch\": ep, \"SR_PSNR/loss\": avg_loss, \"SR_PSNR/psnr\": avg_psnr, \"SR_PSNR/ssim\": avg_ssim})\n",
    "        \n",
    "        if ep % 5 == 0:\n",
    "            log_sr_samples(g, val_loader, ep, \"PSNR\")\n",
    "            state_dict = g.module.state_dict() if gpu_count > 1 else g.state_dict()\n",
    "            torch.save(state_dict, f'/kaggle/working/g_psnr_ep{ep}.pth')\n",
    "            wandb.save(f'/kaggle/working/g_psnr_ep{ep}.pth', base_path='/kaggle/working/')  # Fix wandb warning\n",
    "    \n",
    "    return g\n",
    "\n",
    "def log_sr_samples(g, val_loader, epoch, phase):\n",
    "    g.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(val_loader))\n",
    "        lr_sample, hr_sample = batch['lr'][:4].to(device), batch['hr'][:4].to(device)\n",
    "        sr_sample = g(lr_sample) if gpu_count == 1 else g.module(lr_sample)\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "        for i in range(4):\n",
    "            axes[i,0].imshow(lr_sample[i].permute(1,2,0).cpu()); axes[i,0].set_title('LR'); axes[i,0].axis('off')\n",
    "            axes[i,1].imshow(sr_sample[i].permute(1,2,0).cpu().clamp(0,1)); axes[i,1].set_title('SR'); axes[i,1].axis('off')\n",
    "            axes[i,2].imshow(hr_sample[i].permute(1,2,0).cpu()); axes[i,2].set_title('HR'); axes[i,2].axis('off')\n",
    "        plt.suptitle(f\"{phase} Samples - Epoch {epoch}\")\n",
    "        wandb.log({f\"SR_{phase}/samples\": wandb.Image(fig)})\n",
    "        plt.close()\n",
    "\n",
    "print(\"Starting PSNR pre-training...\")\n",
    "g = train_psnr(g, train_loader, config['sr_epochs_psnr'])\n",
    "print(\"PSNR pre-training finished.\")\n",
    "\n",
    "# GAN Fine-Tuning with AMP & WandB (Fixed Grad Flow)\n",
    "def train_gan(g, d, loader, epochs, g_lr=1e-4, lambda_perc=10.0):\n",
    "    g_opt = optim.Adam(g.parameters(), lr=g_lr)\n",
    "    d_opt = optim.Adam(d.parameters(), lr=config['d_lr'])\n",
    "    scaler_g = GradScaler()\n",
    "    scaler_d = GradScaler()\n",
    "    sched_g = optim.lr_scheduler.CosineAnnealingLR(g_opt, T_max=epochs)\n",
    "    sched_d = optim.lr_scheduler.CosineAnnealingLR(d_opt, T_max=epochs)\n",
    "    adv = nn.BCEWithLogitsLoss().to(device)\n",
    "    l1 = nn.L1Loss().to(device)\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        g.train(); d.train()\n",
    "        tot_g_loss, tot_d_loss = 0, 0\n",
    "        pbar = tqdm(loader, desc=f\"GAN Ep {ep+1}/{epochs}\")\n",
    "        for i, batch in enumerate(pbar):\n",
    "            lr_imgs, hr_imgs = batch['lr'].to(device), batch['hr'].to(device)\n",
    "            \n",
    "            # D Training (Fix: No detach on own preds; only opponent's mean)\n",
    "            d_opt.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                real_pred = d(hr_imgs)  # Keep grad\n",
    "                fake = g(lr_imgs).detach()  # Detach for D\n",
    "                fake_pred = d(fake)  # Keep grad\n",
    "                d_loss = (adv(real_pred - fake_pred.mean().detach(), torch.ones_like(real_pred)) +  # Detach opponent's mean for stability\n",
    "                          adv(fake_pred - real_pred.mean().detach(), torch.zeros_like(fake_pred))) / 2\n",
    "            scaler_d.scale(d_loss).backward()\n",
    "            if (i + 1) % config['accum_steps'] == 0:\n",
    "                scaler_d.step(d_opt)\n",
    "                scaler_d.update()\n",
    "                d_opt.zero_grad()\n",
    "            tot_d_loss += d_loss.item()\n",
    "            \n",
    "            # G Training (Detach D's real_pred mean)\n",
    "            g_opt.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                fake = g(lr_imgs)  # Keep grad\n",
    "                fake_pred = d(fake)  # G sees D output\n",
    "                real_pred = d(hr_imgs).detach()  # Detach for G\n",
    "                g_adv = adv(fake_pred - real_pred.mean(), torch.ones_like(fake_pred))  # No detach on own\n",
    "                g_perc = perc_loss(fake, hr_imgs)\n",
    "                g_l1 = l1(fake, hr_imgs)\n",
    "                g_loss = 0.001 * g_adv + lambda_perc * g_perc + g_l1\n",
    "            scaler_g.scale(g_loss).backward()\n",
    "            if (i + 1) % config['accum_steps'] == 0:\n",
    "                scaler_g.step(g_opt)\n",
    "                scaler_g.update()\n",
    "                g_opt.zero_grad()\n",
    "            tot_g_loss += g_loss.item()\n",
    "            pbar.set_postfix({\"G_Loss\": f\"{g_loss.item():.4f}\", \"D_Loss\": f\"{d_loss.item():.4f}\"})\n",
    "        \n",
    "        avg_g_loss = tot_g_loss / len(loader)\n",
    "        avg_d_loss = tot_d_loss / len(loader)\n",
    "        sched_g.step(); sched_d.step()\n",
    "        \n",
    "        # Quick Val (Fix: No detach in eval)\n",
    "        avg_psnr, avg_ssim = 0, 0\n",
    "        val_iter = iter(val_loader)\n",
    "        for _ in range(5):\n",
    "            try:\n",
    "                batch = next(val_iter)\n",
    "                lr_v, hr_v = batch['lr'].to(device), batch['hr'].to(device)\n",
    "                with torch.no_grad():\n",
    "                    sr_v = g(lr_v) if gpu_count == 1 else g.module(lr_v)\n",
    "                avg_psnr += psnr(sr_v, hr_v)  # No .item()\n",
    "                avg_ssim += compute_ssim(sr_v, hr_v)\n",
    "            except StopIteration:\n",
    "                break\n",
    "        avg_psnr /= 5\n",
    "        avg_ssim /= 5\n",
    "        \n",
    "        wandb.log({\n",
    "            \"SR_GAN/epoch\": ep, \"SR_GAN/g_loss\": avg_g_loss, \"SR_GAN/d_loss\": avg_d_loss,\n",
    "            \"SR_GAN/psnr\": avg_psnr, \"SR_GAN/ssim\": avg_ssim\n",
    "        })\n",
    "        \n",
    "        if ep % 5 == 0:\n",
    "            log_sr_samples(g, val_loader, ep, \"GAN\")\n",
    "            state_dict = g.module.state_dict() if gpu_count > 1 else g.state_dict()\n",
    "            torch.save(state_dict, f'/kaggle/working/g_gan_ep{ep}.pth')\n",
    "            wandb.save(f'/kaggle/working/g_gan_ep{ep}.pth', base_path='/kaggle/working/')  # Fix wandb warning\n",
    "    return g\n",
    "\n",
    "print(\"\\nStarting GAN fine-tuning...\")\n",
    "g = train_gan(g, d, train_loader, config['sr_epochs_gan'])\n",
    "print(\"GAN fine-tuning finished.\")\n",
    "\n",
    "# Save Final SR Model\n",
    "state_dict = g.module.state_dict() if gpu_count > 1 else g.state_dict()\n",
    "torch.save(state_dict, '/kaggle/working/sr_model.pth')\n",
    "wandb.save('/kaggle/working/sr_model.pth', base_path='/kaggle/working/')\n",
    "print(\"SR Model saved & logged to WandB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-26T11:52:16.856232Z",
     "iopub.status.idle": "2025-10-26T11:52:16.856510Z",
     "shell.execute_reply": "2025-10-26T11:52:16.856398Z",
     "shell.execute_reply.started": "2025-10-26T11:52:16.856382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# RobustClassifier with SE (ResNet-inspired)\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, c, r=16):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(c, c//r), nn.ReLU(), nn.Linear(c//r, c), nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * self.fc(x.mean([2,3], keepdim=True))\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_c, out_c, 3, stride, 1)\n",
    "        self.bn = nn.BatchNorm2d(out_c)\n",
    "        self.se = SEBlock(out_c)\n",
    "        self.shortcut = nn.Conv2d(in_c, out_c, 1, stride) if stride > 1 or in_c != out_c else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.se(self.bn(self.conv(x))) + self.shortcut(x))\n",
    "\n",
    "class RobustClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=19):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, 2, 3); self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = nn.Sequential(*[BasicBlock(64, 64) for _ in range(3)])\n",
    "        self.layer2 = nn.Sequential(BasicBlock(64, 128, 2), *[BasicBlock(128, 128) for _ in range(2)])\n",
    "        self.layer3 = nn.Sequential(BasicBlock(128, 256, 2), *[BasicBlock(256, 256) for _ in range(5)])\n",
    "        self.layer4 = nn.Sequential(BasicBlock(256, 512, 2), *[BasicBlock(512, 512) for _ in range(2)])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x); x = self.layer2(x); x = self.layer3(x); x = self.layer4(x)\n",
    "        return self.fc(self.pool(x).flatten(1))\n",
    "    \n",
    "    def get_embeddings(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x); x = self.layer2(x); x = self.layer3(x); x = self.layer4(x)\n",
    "        return self.pool(x).flatten(1)\n",
    "\n",
    "# AL Helpers\n",
    "def get_embeddings(clf, loader, sr_model):\n",
    "    clf.eval(); sr_model.eval()\n",
    "    embeds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Extracting Embeds\"):\n",
    "            imgs = sr_model(batch['lr'].to(device)) if sr_model else batch['lr'].to(device)  # Use SR for AL\n",
    "            emb = clf.module.get_embeddings(imgs) if gpu_count > 1 else clf.get_embeddings(imgs)\n",
    "            embeds.append(emb.cpu().numpy())\n",
    "            labels.append(batch['label'].numpy())\n",
    "    return np.concatenate(embeds), np.concatenate(labels)\n",
    "\n",
    "def dbss_select(unlabeled_embs, labeled_embs, labels, n_select, pin_ratio=0.4):\n",
    "    centroids = [labeled_embs[labels == i].mean(0) for i in range(config['num_classes']) if len(labeled_embs[labels == i]) > 0]\n",
    "    centroids = np.stack(centroids) if centroids else np.zeros((config['num_classes'], labeled_embs.shape[1]))\n",
    "    dists = np.linalg.norm(unlabeled_embs[:, None] - centroids[None], axis=2)\n",
    "    inner_scores = -np.sum(dists, axis=1)  # Favor low dist (inner-class)\n",
    "    border_scores = np.abs(np.sort(dists, axis=1)[:,0] - np.sort(dists, axis=1)[:,1])\n",
    "    inner_top = np.argsort(inner_scores)[-int(n_select * pin_ratio):]\n",
    "    border_top = np.argsort(border_scores)[-int(n_select * (1-pin_ratio)):]\n",
    "    return np.unique(np.concatenate([inner_top, border_top]))[:n_select]\n",
    "\n",
    "def ssas_pseudo(student, teacher, sr_model, unlabeled_loader):\n",
    "    student.eval(); teacher.eval(); sr_model.eval()\n",
    "    consistent = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(unlabeled_loader, desc=\"SSAS\"):\n",
    "            imgs = sr_model(batch['lr'].to(device))\n",
    "            s_pred = torch.argmax(student(imgs), 1)\n",
    "            t_pred = torch.argmax(teacher(imgs), 1)\n",
    "            mask = s_pred == t_pred\n",
    "            consistent.extend(batch['idx'][mask].tolist())  # Assume 'idx' in batch\n",
    "    return consistent[:len(unlabeled_loader) * config['batch_size'] // 2]  # Limit\n",
    "\n",
    "def train_classifier(clf, loader, epochs):\n",
    "    clf.train()\n",
    "    opt = optim.Adam(clf.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    for ep in range(epochs):\n",
    "        tot_loss = 0\n",
    "        pbar = tqdm(loader, desc=f\"CLF Ep {ep+1}/{epochs}\")\n",
    "        for batch in pbar:\n",
    "            imgs, lbls = batch['lr'].to(device), batch['label'].to(device)  # Use SR in full loop\n",
    "            opt.zero_grad()\n",
    "            outputs = clf(imgs)\n",
    "            loss = criterion(outputs, lbls)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tot_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "        # Fixed: Remove local_rank check - just log directly\n",
    "        wandb.log({\"AL_Train/loss\": tot_loss / len(loader)})\n",
    "    return clf\n",
    "\n",
    "def evaluate_model(clf, loader, sr_model=None):\n",
    "    clf.eval()\n",
    "    preds, lbls = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Eval\"):\n",
    "            imgs = sr_model(batch['lr'].to(device)) if sr_model else batch['lr'].to(device)\n",
    "            outputs = clf(imgs)\n",
    "            pred = torch.argmax(outputs, 1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            lbls.extend(batch['label'].numpy())\n",
    "    acc = (np.array(preds) == np.array(lbls)).mean() * 100\n",
    "    return acc, preds, lbls\n",
    "\n",
    "def log_umap(labeled_embs, labeled_lbls, unlabeled_embs, dbss_idx, ssas_idx, cycle):\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "    all_embs = np.concatenate([labeled_embs, unlabeled_embs])\n",
    "    all_lbls = np.concatenate([labeled_lbls, -1 * np.ones(len(unlabeled_embs))])\n",
    "    emb_2d = reducer.fit_transform(all_embs)\n",
    "    fig, ax = plt.subplots(figsize=(14,10))\n",
    "    unlabeled_mask = all_lbls == -1\n",
    "    ax.scatter(emb_2d[unlabeled_mask,0], emb_2d[unlabeled_mask,1], c='lightgray', s=5, label='Unlabeled')\n",
    "    labeled_mask = ~unlabeled_mask\n",
    "    scatter = ax.scatter(emb_2d[labeled_mask,0], emb_2d[labeled_mask,1], c=all_lbls[labeled_mask], cmap='Spectral', s=20)\n",
    "    if dbss_idx.size > 0:\n",
    "        ax.scatter(emb_2d[len(labeled_embs):][dbss_idx], emb_2d[len(labeled_embs):][dbss_idx], c='red', s=100, marker='x', label='DBSS')\n",
    "    if ssas_idx.size > 0:\n",
    "        ax.scatter(emb_2d[len(labeled_embs):][ssas_idx], emb_2d[len(labeled_embs):][ssas_idx], c='lime', s=100, marker='+', label='SSAS')\n",
    "    ax.set_title(f'Feature Space UMAP - Cycle {cycle}')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    # Fixed: Remove local_rank check - just log directly\n",
    "    wandb.log({f\"AL_Cycle_{cycle}/umap\": wandb.Image(fig)})\n",
    "    plt.close()\n",
    "\n",
    "# Placeholder for log_selected_samples, log_confusion_matrix, etc. (adapt from your prev code; log to WandB as Image)\n",
    "def log_confusion_matrix(preds, lbls, names):\n",
    "    cm = confusion_matrix(lbls, preds)\n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues', xticklabels=names[:19], yticklabels=names[:19])  # Truncate if needed\n",
    "    ax.set_xlabel('Predicted'); ax.set_ylabel('True'); ax.set_title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    # Fixed: Remove local_rank check - just log directly\n",
    "    wandb.log({\"AL_ConfMatrix\": wandb.Image(fig)})\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "print(\"AL components defined.\")\n",
    "print(f\"Dual GPU mode: {'Enabled' if gpu_count > 1 else 'Disabled'} ({gpu_count} GPUs detected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-26T11:52:16.857707Z",
     "iopub.status.idle": "2025-10-26T11:52:16.857927Z",
     "shell.execute_reply": "2025-10-26T11:52:16.857825Z",
     "shell.execute_reply.started": "2025-10-26T11:52:16.857815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# SECTION 6: ACTIVE LEARNING PIPELINE\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Load SR for AL (unwrap if DataParallel for saving)\n",
    "# We assume 'g' (the SR model) is already trained and exists in memory from Cell 4\n",
    "if gpu_count > 1:\n",
    "    g.module.load_state_dict(torch.load('/kaggle/working/sr_model.pth'))\n",
    "else:\n",
    "    g.load_state_dict(torch.load('/kaggle/working/sr_model.pth'))\n",
    "g.eval()\n",
    "\n",
    "# Instantiate Classifier with DataParallel for dual T4 GPUs\n",
    "clf = RobustClassifier(num_classes=config['num_classes']).to(device)\n",
    "if gpu_count > 1:\n",
    "    clf = nn.DataParallel(clf)\n",
    "    print(f\"Classifier using DataParallel across {gpu_count} GPUs\")\n",
    "wandb.watch(clf, log=\"all\", log_freq=100)\n",
    "\n",
    "# AL Setup: Initial labeled pool\n",
    "# Use the real labels for stratification from train_idx\n",
    "labeled_indices, unlabeled_indices = train_test_split(\n",
    "    train_idx, \n",
    "    train_size=int(0.1 * len(train_idx)), \n",
    "    stratify=[all_labels[train_idx.index(i)] if i in train_idx else 0 for i in train_idx][:len(train_idx)], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# AL Dataset for subsets (adapt BigEarthNetSR to include idx)\n",
    "class IndexedALDataset(Dataset):\n",
    "    def __init__(self, sr_ds, indices):\n",
    "        self.sr_ds = sr_ds\n",
    "        self.indices = indices\n",
    "    \n",
    "    def __len__(self): return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.sr_ds[self.indices[idx]]\n",
    "        item['idx'] = torch.tensor(self.indices[idx])\n",
    "        return item\n",
    "\n",
    "labeled_loader = DataLoader(IndexedALDataset(train_ds, labeled_indices), batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
    "unlabeled_loader = DataLoader(IndexedALDataset(train_ds, unlabeled_indices), batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
    "\n",
    "teacher = None\n",
    "for cycle in range(config['al_cycles']):\n",
    "    print(f\"\\n--- AL Cycle {cycle+1}/{config['al_cycles']} (Dual T4 GPU Mode) ---\")\n",
    "    wandb.log({\"AL_Cycle\": cycle})\n",
    "    \n",
    "    # Train Classifier (use SR inputs) - optimized for dual GPUs\n",
    "    clf = train_classifier(clf, labeled_loader, config['al_epochs'])\n",
    "    \n",
    "    # Get Embeddings (handle DataParallel for dual GPUs)\n",
    "    def safe_get_embeds(model, loader, sr_model):\n",
    "        model.eval(); sr_model.eval()\n",
    "        embeds, labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Extracting Embeds (Dual GPU)\"):\n",
    "                imgs = sr_model(batch['lr'].to(device)) if sr_model else batch['lr'].to(device)\n",
    "                if gpu_count > 1:\n",
    "                    emb = model.module.get_embeddings(imgs)\n",
    "                else:\n",
    "                    emb = model.get_embeddings(imgs)\n",
    "                embeds.append(emb.cpu().numpy())\n",
    "                labels.append(batch['label'].numpy())\n",
    "        return np.concatenate(embeds), np.concatenate(labels)\n",
    "    \n",
    "    labeled_embs, labeled_lbls = safe_get_embeds(clf, labeled_loader, g)\n",
    "    unlabeled_embs, _ = safe_get_embeds(clf, unlabeled_loader, g)\n",
    "    \n",
    "    # DBSS Selection\n",
    "    n_select = min(int(len(unlabeled_indices) * 0.1), len(unlabeled_embs))\n",
    "    dbss_local_idx = dbss_select(unlabeled_embs, labeled_embs, labeled_lbls, n_select)\n",
    "    newly_labeled_human = [unlabeled_indices[i] for i in dbss_local_idx]\n",
    "    \n",
    "    # SSAS (post-cycle 1)\n",
    "    newly_labeled_pseudo = []\n",
    "    if cycle >= 1 and teacher is not None:\n",
    "        pseudo_local = ssas_pseudo(clf, teacher, g, unlabeled_loader)\n",
    "        newly_labeled_pseudo = [unlabeled_indices[i] for i in pseudo_local if i < len(unlabeled_indices)]\n",
    "    \n",
    "    # Update Pools\n",
    "    all_new = np.concatenate([newly_labeled_human, newly_labeled_pseudo])\n",
    "    labeled_indices = np.concatenate([labeled_indices, all_new])\n",
    "    unlabeled_indices = np.setdiff1d(unlabeled_indices, all_new)\n",
    "    \n",
    "    # Log Visuals (UMAP)\n",
    "    log_umap(labeled_embs, labeled_lbls, unlabeled_embs, dbss_local_idx, np.array(pseudo_local) if 'pseudo_local' in locals() else np.array([]), cycle)\n",
    "    \n",
    "    # Update Teacher (deepcopy handles DataParallel)\n",
    "    teacher = copy.deepcopy(clf)\n",
    "    \n",
    "    # Cycle Eval (handle DataParallel for dual GPUs)\n",
    "    def safe_eval(model, loader, sr_model):\n",
    "        model.eval()\n",
    "        preds, lbls = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Eval (Dual GPU)\"):\n",
    "                imgs = sr_model(batch['lr'].to(device)) if sr_model else batch['lr'].to(device)\n",
    "                outputs = model(imgs)\n",
    "                pred = torch.argmax(outputs, 1)\n",
    "                preds.extend(pred.cpu().numpy())\n",
    "                lbls.extend(batch['label'].numpy())\n",
    "        acc = (np.array(preds) == np.array(lbls)).mean() * 100\n",
    "        return acc, preds, lbls\n",
    "    \n",
    "    val_acc, val_preds, val_lbls = safe_eval(clf, val_loader, g)\n",
    "    wandb.log({f\"AL_Cycle_{cycle}/accuracy\": val_acc})\n",
    "    log_confusion_matrix(val_preds, val_lbls, [f\"Class_{i}\" for i in range(config['num_classes'])])\n",
    "    print(f\"Cycle {cycle} Val Acc: {val_acc:.2f}% (Dual T4 GPU)\")\n",
    "    \n",
    "    # Update Loaders\n",
    "    labeled_loader = DataLoader(IndexedALDataset(train_ds, labeled_indices), batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
    "    unlabeled_loader = DataLoader(IndexedALDataset(train_ds, unlabeled_indices), batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
    "\n",
    "# Save Classifier (unwrap if DataParallel)\n",
    "save_model(clf, '/kaggle/working/clf_model.pth')\n",
    "\n",
    "print(\"AL Pipeline complete with Dual T4 GPU optimization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-26T11:52:16.858641Z",
     "iopub.status.idle": "2025-10-26T11:52:16.858914Z",
     "shell.execute_reply": "2025-10-26T11:52:16.858813Z",
     "shell.execute_reply.started": "2025-10-26T11:52:16.858798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# SECTION 7: FINAL EVALUATION\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "print(\"Starting final evaluation...\")\n",
    "\n",
    "# We assume 'clf', 'val_loader', and 'g' (SR model) exist from Cell 6\n",
    "# We assume 'psnr' and 'compute_ssim' exist from Cell 3\n",
    "\n",
    "final_acc, final_preds, final_lbls = evaluate_model(clf, val_loader, g)\n",
    "\n",
    "# Calculate final PSNR/SSIM on a subset of the validation loader\n",
    "final_psnr, final_ssim, batch_count = 0, 0, 0\n",
    "val_iter = iter(val_loader)\n",
    "for _ in range(10): # Use 10 batches for a good approximation\n",
    "    try:\n",
    "        batch = next(val_iter)\n",
    "        lr_v, hr_v = batch['lr'].to(device), batch['hr'].to(device)\n",
    "        with torch.no_grad():\n",
    "            sr_v = g(lr_v) if world_size == 1 else g.module(lr_v)\n",
    "        final_psnr += psnr(sr_v, hr_v)\n",
    "        final_ssim += compute_ssim(sr_v, hr_v)\n",
    "        batch_count += 1\n",
    "    except StopIteration:\n",
    "        break # Stop if val_loader has fewer than 10 batches\n",
    "    except Exception as e:\n",
    "        print(f\"Error in final eval: {e}\")\n",
    "\n",
    "final_psnr /= batch_count\n",
    "final_ssim /= batch_count\n",
    "\n",
    "# (FIXED) Removed `if local_rank == 0:` as this is not distributed training\n",
    "wandb.log({\n",
    "    \"final/psnr\": final_psnr, \"final/ssim\": final_ssim,\n",
    "    \"final/accuracy\": final_acc\n",
    "})\n",
    "\n",
    "# Summary Table\n",
    "table = wandb.Table(columns=[\"Metric\", \"Value\"])\n",
    "table.add_data([\"PSNR (dB)\", f\"{final_psnr:.2f}\"])\n",
    "table.add_data([\"SSIM\", f\"{final_ssim:.3f}\"])\n",
    "table.add_data([\"AL Accuracy (%)\", f\"{final_acc:.2f}\"])\n",
    "wandb.log({\"final/summary\": table})\n",
    "\n",
    "print(f\"Final PSNR: {final_psnr:.2f} | SSIM: {final_ssim:.3f} | AL Acc: {final_acc:.2f}%\")\n",
    "\n",
    "wandb.finish()\n",
    "print(\"Pipeline complete! Check WandB dashboard for full logs/visuals.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 705367,
     "sourceId": 1231934,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5872309,
     "sourceId": 9621334,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 479817,
     "modelInstanceId": 464024,
     "sourceId": 617219,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
